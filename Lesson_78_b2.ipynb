{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poudyaldiksha/Data-Science-project/blob/main/Lesson_78_b2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMnFgNSHZAiR"
      },
      "source": [
        "# Vectors\n",
        "\n",
        "The next step is to calculate the eigenvectors and eigenvalues. But before that, you need to learn about vectors.\n",
        "\n",
        "**Q:** What is a vector?\n",
        "\n",
        "**A vector is an object that has magnitude as well as direction**. For example, consider the following two statements:\n",
        "\n",
        "*Statement 1: Nikhil is driving his car at a speed of $6$ Km/hr*\n",
        "\n",
        "*Statement 2: Nikhil is driving his car towards **east** on M.G. Road at a speed of $6$ Km/hr*\n",
        "\n",
        "Whenever we attach direction to an object it becomes a **vector**. The figure below illustrates statement 2.\n",
        "\n",
        "<br>\n",
        "\n",
        "<center> <img src=https://s3-whjr-v2-prod-bucket.whjr.online/dc952b93-c716-492c-ba50-add03a143fc2.png width=500></center>\n",
        "\n",
        "The figure above represents the **Velocity** of the car.\n",
        "\n",
        "**Q:** What is Velocity?\n",
        "\n",
        "**A:** Velocity is a measure of how fast something moves in a particular direction.\n",
        "\n",
        "Hence, direction becomes an important factor. Speed is only half the information on velocity and direction is the other half.\n",
        "\n",
        "The <b><font color ='maroon'>velocity arrow</font></b> (Velocity vector) indicates the direction of the vehicle and the length of the line joining A to B indicates the magnitude (speed).\n",
        "\n",
        "Hence we can picture a vector as a directed line segment, the length of which determines the magnitude of the vector and the arrow indicates the direction. The direction of the vector is always from its tail to its head.\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/758d2ad5-9009-4c38-a341-9575baedec35.png width=500></center>\n",
        "\n",
        "The **Tail** is the starting point of the vector and the **Head** is the terminating point of the vector.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Vectors in 3-D space:**\n",
        "\n",
        "Consider an aeroplane taking off from Mumbai airport and flying to New Delhi airport. Here we need to specify $x, y,$ and $z$ coordinates to specify its location and velocity.\n",
        "\n",
        "<center> <img src=https://s3-whjr-v2-prod-bucket.whjr.online/b4e1dcb2-85ab-4a57-aab0-0b132fbadf66.png width=1000></center>\n",
        "\n",
        "As we know Mumbai is located in the southern part of India relative to New Delhi, we can say that the plane has to fly back to the North to reach New Delhi airport. During take-off say,  the target is to reach a certain height represent by point $B$ from the origin which is at Mumbai Airport.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtIjVBU4JyjC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PulUbAIzJzFG"
      },
      "source": [
        "#### Vector Representation\n",
        "\n",
        "Let's see how to define vectors. In the above aeroplane example, we had an intermediate point $B$ in the 3-D space, the coordinates of which are:\n",
        "\n",
        "\\begin{align}\n",
        "B = (-5,1.5,1)\n",
        "\\end{align}\n",
        "\n",
        "If we draw a vector to this point from origin $A$, the vector can be described as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec{AB} = \\begin{bmatrix}-5\\\\ 1.5\\\\ 1 \\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "**Note:** The $\\rightarrow$ on $AB$ indicates that the object $AB$ is a vector.\n",
        "\n",
        "Now let's define this vector by creating a NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPnuvLy5J2mA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6141f2d6-23bf-47c7-c9be-4ec076af674b"
      },
      "source": [
        "# Create a 3D vector\n",
        "import numpy as np\n",
        "vector_AB = np.array([-5, 1.5, 1])\n",
        "print(vector_AB)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-5.   1.5  1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(vector_AB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYs0GId39RVE",
        "outputId": "bf8c6c52-1f5f-46f1-be1d-2853f818d8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQRRLAtcJ_m-"
      },
      "source": [
        "Here we see a vector in a 3-dimensional space. We can easily visualise the vectors in $2$ or $3$ dimensions, however, vectors can exist in higher dimensions as well.\n",
        "\n",
        "When we have more than $3$ features in our dataset,  the elements in the array will also increase. For example, considering the wheat kernel dataset:\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/2a82f726-ccea-45cd-91ce-b2d8edce8535.png width=900></center>\n",
        "\n",
        "If we represent row $1$ in vector form it would be a 7-dimensional vector. It can be represented as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec {X_1} = \\begin{bmatrix}14.88\\\\ 14.57\\\\ 0.8811\\\\ 5.554\\\\ 3.333\\\\ 1.018\\\\ 4.956\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Let's define this 7-dimensional vector by again creating a NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcs_3vmeKMaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299cc038-ca94-4b2b-9c4f-c04c7059bfbf"
      },
      "source": [
        "# Create a 7-dimensional vector.\n",
        "\n",
        "vector_X1 = np.array([14.88, 14.57, 0.8811, 5.554, 3.333, 1.018, 4.956])\n",
        "print('Vector for row 1: ', vector_X1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for row 1:  [14.88   14.57    0.8811  5.554   3.333   1.018   4.956 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOiRhkmJKTmu"
      },
      "source": [
        "So far the vectors we have seen start from the origin and hence the coordinates become the vector. *But what if the starting point is not the origin?*\n",
        "\n",
        " If the starting point of the vector is point $A(x_A, y_A)$ and the end point is $B(x_B, y_B)$, then the vector $\\vec{AB}$ is represented as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec{AB} &= \\vec{B} - \\vec{A} \\\\\n",
        "&= (x_B - x_A, y_B - y_A)\n",
        "\\end{align}\n",
        "\n",
        "Let us take a simple problem statement to understand this:\n",
        "\n",
        "**Statement**: You start from your home, pick up some burgers from McDonald's and go to your friend's home for a party.\n",
        "\n",
        "Let us represent this using vectors.\n",
        "\n",
        "<center> <img src=https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/bf75e1b4-5af7-49b2-b081-a8618f34f4c9.png width=650></center>\n",
        "\n",
        "The image above describes the problem statement. The coordinates for various locations are:\n",
        "\n",
        "1. Home $(x_h, y_h) = (0,0)$\n",
        "\n",
        "2. McD $(x_m, y_m) = (6, 1.5)$\n",
        "\n",
        "3. Party $(x_p, y_p) = (4, 4)$\n",
        "\n",
        "The vector for Home to McD is calculated as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec{hm} &= \\text{McD} - \\text{Home} \\\\\n",
        "&= (x_m - x_h, y_m - y_h) \\\\\n",
        "&= \\begin{bmatrix} 6 - 0 \\\\ 1.5 - 0 \\end{bmatrix} \\\\\n",
        "&= \\begin{bmatrix} 6\\\\ 1.5\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Similarly, the vector for McD to Party is calculated as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec{mp} &= \\text{Party} - \\text{McD} \\\\\n",
        "&= (x_p - x_m, y_p - y_m) \\\\\n",
        "&= \\begin{bmatrix}4 - 6 \\\\ 4 - 1.5 \\end{bmatrix} \\\\\n",
        "&= \\begin{bmatrix} -2\\\\ 2.5\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "The negative sign indicates that you have to ride the motorbike into another direction to reach your destination.\n",
        "\n",
        "The same can be calculated using `numpy` module. For this, first define the coordinates for Home, McD and Party place as follows:\n",
        "\n",
        "- `home = array([0, 0])`\n",
        "\n",
        "- `mcd = array([6, 1.5])`\n",
        "\n",
        "- `party = array([4, 4])`\n",
        "\n",
        "Next obtain the respective vectors by subtracting the starting-point coordinates from the ending-point coordinates, Hence:\n",
        "\n",
        "- $\\vec{hm}$ will be calculated as `mcd - home`\n",
        "\n",
        "- $\\vec{mp}$ will be calculated as `party - mcd`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLiEJCoRK8o6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cc372b-6d5d-4bb3-952d-b2de37e94cb8"
      },
      "source": [
        "# Obtaining Vectors from Coordinates\n",
        "\n",
        "# Define the coordinates\n",
        "home = np.array([0, 0])\n",
        "mcd = np.array([6, 1.5])\n",
        "party = np.array([4, 4])\n",
        "\n",
        "# Obtain the respective Vectors\n",
        "hm = mcd - home\n",
        "mp = party - mcd\n",
        "\n",
        "print('Vector from Home to McD is: ', hm)\n",
        "print('Vector from McDonalds to Party place is: ', mp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector from Home to McD is:  [6.  1.5]\n",
            "Vector from McDonalds to Party place is:  [-2.   2.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, we calculated the vector $\\vec{hm}$  and $\\vec{mp}$ by subtracting the starting-point coordinates from the ending-point coordinates."
      ],
      "metadata": {
        "id": "tNTtI7dhGzVp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w2aPgWdj9-9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0fTeahJK-xY"
      },
      "source": [
        "**Vector Magnitude**\n",
        "\n",
        "Now that we know about vector representation let us see how to calculate magnitude (also referred to as **norm**) of a vector. Recall the vector representation:\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/758d2ad5-9009-4c38-a341-9575baedec35.png width=500></center>\n",
        "\n",
        "Consider a vector starting from point $A = (x_A, y_A)$ and the terminating at point $B = (x_B, y_B)$. The magnitude/norm of a vector $\\vec{AB}$ is defined as:\n",
        "\n",
        "\\begin{align}\n",
        "|\\vec{AB}| = \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}\n",
        "\\end{align}\n",
        "\n",
        "Similarly consider the above vector $\\vec{hm}$:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec{hm} = \\begin{bmatrix} 6\\\\ 1.5\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "The magnitude of vector $\\vec{hm}$ will be calculated as:\n",
        "\n",
        "\\begin{align}\n",
        "|\\vec{hm}| =& \\sqrt{(x)^2 + (y)^2} \\\\\n",
        "&= \\sqrt{6^2 + 1.5^2}  \\\\\n",
        "&= \\sqrt{36 + 2.25} \\\\\n",
        "&= \\sqrt{38.25} \\\\\n",
        "&= 6.1846\n",
        "\\end{align}\n",
        "\n",
        "<br>\n",
        "\n",
        "Similarly, consider an $n^{th}$ dimensional vector represented as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec V = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .. \\\\ .. \\\\ .. \\\\ x_n\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "The norm of vector $\\vec V$ will be calculated as:\n",
        "\n",
        "\\begin{align}\n",
        "|\\vec V| = \\sqrt{{x_1}^2 + {x_2}^2 + ..... +{x_n}^2}\n",
        "\\end{align}\n",
        "\n",
        "For example, the 7-dimensional vector $\\vec {X_1}$ represented by:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec {X_1} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6 \\\\ x_7 \\end{bmatrix} =  \\begin{bmatrix}14.88\\\\ 14.57\\\\ 0.8811\\\\ 5.554\\\\ 3.333\\\\ 1.018\\\\ 4.956\\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "The norm of the vector $\\vec {X_1}$ will be defined as:\n",
        "\n",
        "\\begin{align}\n",
        "|\\vec {X_1}| &= \\sqrt{{x_1}^2 + {x_2}^2 + {x_3}^2 + {x_4}^2 + {x_5}^2 + {x_6}^2 + {x_7}^2} \\\\\n",
        "&= \\sqrt{14.88^2 + 14.57^2 + 0.8811^2 + 5.554^2 + 3.33^2 + 1.018^2 + 4.956^2} \\\\\n",
        "&= \\sqrt{221.4144 + 212.2849 + 0.776 + 30.847 + 11.11 + 1.036 + 24.562} \\\\\n",
        "&= \\sqrt{502.0303} \\\\\n",
        "&= 22.406\n",
        "\\end{align}\n",
        "\n",
        "<br>\n",
        "\n",
        "The `linalg.norm()` function of `numpy` is used to calculate the norm of vectors. Let us calculate the norm of vector `X1` using this function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_X1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YYLq9qYskga",
        "outputId": "3853bf9e-10c8-41c5-edd8-e2f6ee7785ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14.88  , 14.57  ,  0.8811,  5.554 ,  3.333 ,  1.018 ,  4.956 ])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RXnJFZuOPXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37e60f9-dcdf-4cc4-df0e-d1833ea1c0d9"
      },
      "source": [
        "# Calculate the norm of a vector X1\n",
        "print('For the vector X1: ', vector_X1)\n",
        "print('Norm of vector is: ', np.linalg.norm(vector_X1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the vector X1:  [14.88   14.57    0.8811  5.554   3.333   1.018   4.956 ]\n",
            "Norm of vector is:  22.406019329858662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZmpEQENo2X"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x0KkBnUMDDW"
      },
      "source": [
        "**Components of a Vector**\n",
        "\n",
        "Consider a 2-dimensional vector $\\vec u$:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec u = \\begin{bmatrix} u_x \\\\ u_y \\end{bmatrix} = \\begin{bmatrix} 5 \\\\ 5 \\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/13368db4-600d-4571-b20c-e5ca1bc9418d.png width=500></center>\n",
        "\n",
        "Let's say we are riding our bike along the vector $\\vec u$ in the above figure. This means the effective direction in which we are riding will be **North-East**.  This indicates that we would also be moving:\n",
        "\n",
        "- In the East direction - indicated by $\\vec {U_x}$.\n",
        "\n",
        "- At the same time, in the North direction - indicated by $\\vec {U_y}$.\n",
        "\n",
        "The $\\vec {U_x}$ and $\\vec {U_y}$ are known as **vector components** or **projections**. Any given $n$-dimensional vector can always be represented by its $n$ components/projections.\n",
        "\n",
        "**Vector Angle:**\n",
        "\n",
        "The vector angle gives us a sense of direction for any given vector. In the above figure, the vector angle is indicated as $\\theta$. It is the angle a vector makes with the horizontal-axis ($x$-axis).\n",
        "\n",
        "The vector angle $\\theta$ can easily be calculated with the help of trigonometry ratios:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{tan} \\space \\theta = \\frac{\\text{Perpendicular}}{\\text{Base}}\n",
        "\\end{align}\n",
        "\n",
        "For the vector $\\vec u$ this can be written as:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{tan} \\space \\theta &= \\frac{|\\vec {U_y|}}{|\\vec {U_x}|} \\\\\n",
        "&= \\frac{5}{5} \\\\\n",
        "&= 1 \\\\\n",
        "\\Rightarrow \\theta &= 45^o\n",
        "\\end{align}\n",
        "\n",
        "<br>\n",
        "\n",
        "We can also define a vector with the help of it's **magnitude** and **angle**.\n",
        "\n",
        "For the vector $\\vec u$, the magnitude be:\n",
        "\n",
        "\\begin{align}\n",
        "|\\vec u| = \\sqrt{5^2 +5^2} = \\sqrt {25+25} = \\sqrt{50} = 7.07\n",
        "\\end{align}\n",
        "\n",
        "**The vector $\\vec u$ can also be represented as:**\n",
        "\n",
        "\\begin{align}\n",
        "\\vec u = \\begin{cases} |\\vec u| = 7.07 \\\\ \\theta = 45^o \\end{cases}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "**Q**: How to calculate components of vectors if you are given with the above representation?\n",
        "\n",
        "**A**: We can calculate the components of vectors using the trigonometric ratios.\n",
        "\n",
        "**Trigonometric Ratios:**\n",
        "The Trigonometry ratios of an angle $\\theta$ in a right-angled triangle are defined as:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{sin} \\space \\theta &= \\frac{\\text {Perpendicular}}{\\text {Hypotenuse}}\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "\\text{cos} \\space \\theta &= \\frac{\\text {Base}}{\\text {Hypotenuse}}\n",
        "\\end{align}\n",
        "\n",
        "For the angle $\\theta$ in the above image,\n",
        "\n",
        "- $\\text{Perpendicular} = \\vec{u_y}$\n",
        "- $\\text{Base} = \\vec{u_x}$\n",
        "- $\\text{Hypotenuse} = \\vec{u}$\n",
        "\n",
        "Thus,\n",
        "\n",
        "\\begin{align}\n",
        "\\text{sin} \\space \\theta &= \\frac{|\\vec u_y|}{|\\vec u|}\n",
        "\\end{align}\n",
        "\n",
        "Similarly,\n",
        "\n",
        "\\begin{align}\n",
        "\\text{cos} \\space \\theta &=  \\frac{|\\vec u_x|}{|\\vec u|}\n",
        "\\end{align}\n",
        "\n",
        "Hence, if we are given with magnitude of a vector ($|\\vec u|$) and angle ($\\theta$), we can find the component of the vectors ($|\\vec u_x|$ and $|\\vec u_y|$) using the above trigonometric ratios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDHWsW_Bvu0W"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g84SC_Jgw3c"
      },
      "source": [
        "#### Activity 1: Scaling of Vectors\n",
        "\n",
        "\n",
        "A **scalar** is an object that does not have any direction and is described with magnitude only. For example, if we want to describe $1$ Kg of apple we do not need its direction.\n",
        "\n",
        "Since the scalar does not have any direction, when we multiply a vector by a scalar it is called **scaling** a vector, because we specify how big or small the vector is.\n",
        "\n",
        "For example consider the following vector $\\vec a$:\n",
        "\n",
        "\\begin{align}\n",
        "a = \\begin{bmatrix} 2 \\\\ 3 \\\\ 6 \\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Let's say we have a scalar number $k = 1.5$\n",
        "\n",
        "The multiplication of scalar to the vector can be calculated as:\n",
        "\n",
        "\\begin{align}\n",
        "k \\times a = 1.5 \\times \\begin{bmatrix} 2 \\\\ 3 \\\\ 6 \\end{bmatrix} = \\begin{bmatrix} 1.5 \\times 2 \\\\ 1.5 \\times 3 \\\\ 1.5 \\times 6 \\end{bmatrix}  = \\begin{bmatrix} 3 \\\\ 4.5 \\\\ 9 \\end{bmatrix}\n",
        "\\end{align}\n",
        "\n",
        "The scalar multiplication can be described as:\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/d5ee857c-2300-4508-a5d8-ebd5d257b81a.png></center>\n",
        "\n",
        "**Note:** The direction of a vector is unaffected by scalar multiplication.\n",
        "\n",
        "\n",
        "We can perform this operation directly using the NumPy array. For example,  create a vector $\\vec{a}= \\begin{bmatrix} 2 \\\\ 3 \\\\ 6 \\end{bmatrix}$ and scale this vector by a magnitude of $1.5$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b1VdrcMhrzs",
        "outputId": "46855ba4-58b0-41c5-a77f-873b489fda97"
      },
      "source": [
        "#  Scaling a vector\n",
        "\n",
        "# Define vector 'a'\n",
        "a = np.array([2, 3, 6])\n",
        "print(\"Original vector:\", a)\n",
        "# Define scalar\n",
        "k = 1.5\n",
        "print(\"Scalar magnitude:\", k)\n",
        "# multiplication\n",
        "scaled_vec = k * a\n",
        "print(\"Scaled vector:\", scaled_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original vector: [2 3 6]\n",
            "Scalar magnitude: 1.5\n",
            "Scaled vector: [3.  4.5 9. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, `scalar magnitude` is multiplied with each values of `Original vector` that gives `Scaled vector`."
      ],
      "metadata": {
        "id": "4AwR_85zUdZJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG4dFtrKjclU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBx533VXjf47"
      },
      "source": [
        "#### Activity 2: Unit Vector\n",
        "\n",
        "A vector that has a magnitude of 1 is known as a **unit vector**. It is represented by the symbol **^**, which is called a cap or hat. For example, the unit vector of a vector $\\vec a$ is represented as $\\hat{a}$.\n",
        "\n",
        "The unit vector has the same direction coordinates as that of the given vector. It is also known as **direction vector** as it determines only direction.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/7147cb35-d4c8-49f4-b48b-53e9fe140b86.png\" width=350/></center>\n",
        "\n",
        "The unit vector $\\hat{a}$ of $\\vec a$ is obtained by dividing the vector $\\vec a$ with its magnitude as follows:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "  \\hat{a}=\\frac{\\vec{a}}{\\left | \\vec{a} \\right |}\n",
        "\\end{align}\n",
        "\n",
        "Consider a vector $\\vec{A} = (12, 3, 4)$.\n",
        "\n",
        "Thus, unit vector of $\\vec{A}$ is calculated as:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\hat{A} &=\\frac{\\vec{A}}{\\left | \\vec{A} \\right |} \\\\\n",
        "&= \\frac{(12, 3, 4)}{\\left | \\sqrt{12^2 + 3^2 + 4^2} \\right |} \\\\\n",
        "&= \\frac{(12, 3, 4)}{\\left | \\sqrt{169} \\right |} \\\\\n",
        "&= \\frac{(12, 3, 4)}{13} \\\\\n",
        "\\end{align}\n",
        "\n",
        "Thus,\n",
        "\\begin{align}\n",
        "\\hat{A} &= \\bigg(\\frac{12}{13}, \\frac{3}{13}, \\frac{4}{13} \\bigg)\n",
        "\\end{align}\n",
        "\n",
        "If we calculate $|\\hat{A}|$, we will find that it is equal to $1$. In this way, you can obtain the unit vector of any given vector.\n",
        "\n",
        "Let us normalise the above vector $\\vec{A}$ to its unit vector by first calculating its magnitude (norm) using `np.linalg.norm()` function and then dividing the vector $\\vec{A}$ by this norm value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqIFnVm10IjD",
        "outputId": "25c73ac4-8818-42fe-8f03-ac55bd7542bc"
      },
      "source": [
        "#  Obtain unit vector of 'A'\n",
        "\n",
        "A = np.array([12, 3, 4])\n",
        "print(\"Orginal vector:\", A)\n",
        "unit_vecA = A / np.linalg.norm(A)\n",
        "print(\"Unit vector:\", unit_vecA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orginal vector: [12  3  4]\n",
            "Unit vector: [0.92307692 0.23076923 0.30769231]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frgWNo-XwR94"
      },
      "source": [
        "Hence, we obtained the same value of unit vector as that obtained mathematically.\n",
        "\n",
        "Suppose unit vector $\\hat{A}$ is a column matrix:\n",
        "\n",
        "$$\\hat{A}= \\begin{bmatrix} \\frac{12}{13} \\\\ \\frac{3}{13} \\\\ \\frac{4}{13} \\end{bmatrix}$$\n",
        "\n",
        "Transpose of this matrix would be:\n",
        "\n",
        "$$\\hat{A}^T= \\begin{bmatrix} \\frac{12}{13} & \\frac{3}{13} & \\frac{4}{13} \\end{bmatrix}$$\n",
        "\n",
        "If we multiply these two vectors i.e $\\hat{A}. \\hat{A}^T$:\n",
        "\n",
        "$$\\hat{A}. \\hat{A}^T$$\n",
        "\n",
        "\\begin{align}  \n",
        "\\hat{A}. \\hat{A}^T &= \\begin{bmatrix} \\frac{12}{13} \\\\ \\frac{3}{13} \\\\ \\frac{4}{13} \\end{bmatrix} \\begin{bmatrix} \\frac{12}{13} & \\frac{3}{13} & \\frac{4}{13} \\end{bmatrix} \\\\\n",
        "&= \\begin{bmatrix}\\frac{144}{169} & \\frac{9}{169} & \\frac{16}{169} \\end{bmatrix} \\\\\n",
        "&= \\begin{bmatrix}\\frac{169}{169}  \\end{bmatrix} \\\\\n",
        "&= 1\n",
        "\\end{align}  \n",
        "\n",
        "\\begin{equation}\n",
        "\\boxed{\\hat{A}. \\hat{A}^T= 1}\n",
        "\\end{equation}\n",
        "\n",
        "Thus, product of  a unit vector with its transpose is always equal to $1$.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXV3-p8L2Ns1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1YsBdHmHruP"
      },
      "source": [
        "#### Activity 3: Vector Products\n",
        "\n",
        "Vectors can be multiplied in the following ways:\n",
        "\n",
        "1. Vector product or Cross product:\n",
        "    \n",
        "    A cross product is used when we need the result to be a vector quantity. In essence the cross product describes how much the two vectors point in different directions.\n",
        "\n",
        "2. Scalar product or Dot product:\n",
        "\n",
        "    A dot product is used when we need the result to be a scalar quantity. In essence the dot product describes how much the vectors points in same direction.\n",
        "\n",
        "Assume two vectors $\\vec A$ and $\\vec B$ defined in three dimensions as:\n",
        "\n",
        "\\begin{matrix}  \n",
        "{\\vec A} = \\begin{bmatrix} A_x \\\\ A_y \\\\ A_z \\end{bmatrix} &\n",
        "{\\vec B} = \\begin{bmatrix} B_x \\\\ B_y \\\\ B_z \\end{bmatrix}\n",
        "\\tag{3.1}\n",
        "\\end{matrix}  \n",
        "\n",
        "Let's make a grid of the all the possible interactions for these two vectors:\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/732bd190-4509-4a9e-8021-e283cf7b7829.png width=300></center>\n",
        "\n",
        "As the vectors each have 3 componenets we will have a total of $ 3\\times 3 = 9$ interactions where:\n",
        "\n",
        "<center><h4><i>All possible interactions = interactions in similar dimensions + interactions in different dimensions</h4></i></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "1. Dot product: The interactions of the same dimensions gives us the dot product.\n",
        "\n",
        "2. Cross product: The interactions of the different dimensions gives us the cross product.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ugsiDl_ACz"
      },
      "source": [
        "**CROSS PRODUCT OF VECTORS**\n",
        "\n",
        "When two vectors are multiplied with each other and the product of the vectors is also a vector quantity, then the resultant vector is called the cross product of two vectors or the vector product. The resultant vector is perpendicular to the plane containing the two given vectors.\n",
        "\n",
        "Mathematically the **cross product** of two vectors $\\vec A$ and $\\vec B$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec A \\times \\vec B = |\\vec A| \\space |\\vec B| \\space \\text{sin} \\theta \\space \\hat n\n",
        "\\tag{3.2}\n",
        "\\end{equation}\n",
        "\n",
        "Where,\n",
        "\n",
        "$\\theta$ is the angle between vectors $\\vec A$ and $\\vec B$.\n",
        "\n",
        "$\\hat n$ is a unit vector orthogonal (perpendicular) to the plane containing $\\vec A$ and $\\vec B$.\n",
        "\n",
        "**IMPORTANT NOTE :** The direction of the resulting vector is obtained with the help of right hand rule:\n",
        "\n",
        "<img src=https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/b06b8b37-e680-4834-a7a4-57d08aec998e.png width=300>\n",
        "\n",
        "**Right hand rule**: In this rule, if we use our index finger of the right hand in the direction of the first vector and the middle finger in the direction of the second vector. Then, the thumb of the right hand indicates the direction of the cross product of these two vectors.\n",
        "\n",
        "**Cross product in matrix notation:**\n",
        "\n",
        "From equation $3.1$ we have:\n",
        "\n",
        "\\begin{matrix}  \n",
        "{\\vec A} = \\begin{bmatrix} A_x \\\\ A_y \\\\ A_z \\end{bmatrix} &\n",
        "{\\vec B} = \\begin{bmatrix} B_x \\\\ B_y \\\\ B_z \\end{bmatrix}\n",
        "\\end{matrix}\n",
        "\n",
        "The cross product for the matrix can be found by arranging the components of the vectors $\\vec A$ and $\\vec B$ along with the respective dimensions (in this case $x,y, z$) in a matrix form:\n",
        "\n",
        "\\begin{matrix}\n",
        "\\vec A \\times \\vec B = \\begin{bmatrix} x & y & z \\\\ A_x & A_y & A_z \\\\ B_x & B_y & B_z\\end{bmatrix}\n",
        "\\end{matrix}\n",
        "\n",
        "After solving the above matrix we get the cross product as:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec A \\times \\vec B = (A_y B_z - A_z B_y)x - (A_x B_z - A_z B_x)y + (A_x B_y - A_y B_x)z\n",
        "\\end{align}\n",
        "\n",
        "In matrix from this can be represented as:\n",
        "\n",
        "\\begin{matrix}\n",
        "\\vec A \\times \\vec B = \\begin{bmatrix} A_y B_z - A_z B_y \\\\ -(A_x B_z - A_z B_x) \\\\ A_x B_y - A_y B_x \\end{bmatrix} = \\begin{bmatrix} A_y B_z - A_z B_y \\\\ A_z B_x - A_x B_z \\\\ A_x B_y - A_y B_x \\end{bmatrix}\n",
        "\\tag{3.3}\n",
        "\\end{matrix}\n",
        "\n",
        "**Note:**\n",
        "\n",
        "1. Instead of memorising the result $3.3$ obtained above, remember the procedure of getting it.\n",
        "\n",
        "2. Do not confuse matrix multiplication with vector cross product. They both are different.\n",
        "\n",
        "**Direction of the resultant vector:** The resultant vector is always perpendicular to the vectors $\\vec A$ and $\\vec B$. The cross product is mostly used to determine the vector, which is perpendicular (orthogonal) to the plane surface spanned by two vectors.\n",
        "\n",
        "<br>\n",
        "\n",
        "Let's take a simple example to understand this:\n",
        "\n",
        "\\begin{matrix}  \n",
        "{\\vec A} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 3 \\end{bmatrix} &\n",
        "{\\vec B} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3 \\end{bmatrix}\n",
        "\\end{matrix}\n",
        "\n",
        "The resultant vector after applying cross product can be obtained from equation $3.3$:\n",
        "\n",
        "\\begin{matrix}\n",
        "\\vec A \\times \\vec B = \\begin{bmatrix} 2 \\times 3 - 3 \\times 1 \\\\ 3 \\times 2 - 3 \\times 3 \\\\ 3 \\times 1 - 2 \\times 2 \\end{bmatrix}\n",
        "\\end{matrix}\n",
        "\n",
        "\\begin{matrix}\n",
        "\\Rightarrow \\vec A \\times \\vec B = \\begin{bmatrix} 6 - 3 \\\\ 6 - 9 \\\\ 3 - 4 \\end{bmatrix}\n",
        "\\end{matrix}\n",
        "\n",
        "\\begin{matrix}\n",
        "\\Rightarrow \\vec A \\times \\vec B = \\begin{bmatrix} 3 \\\\ -3 \\\\ -1 \\end{bmatrix}\n",
        "\\end{matrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the cross product of two vectors (Ā and B̄)."
      ],
      "metadata": {
        "id": "tKC_p1TuXTf3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsqhjqgeLlsQ",
        "outputId": "a428bcd7-67ee-41ec-b907-caa653052932"
      },
      "source": [
        "# Finding cross product of two vectors\n",
        "\n",
        "# First vector\n",
        "A = np.array([3, 2, 3])\n",
        "print(\"First vector:\", A)\n",
        "\n",
        "# Second vector\n",
        "B = np.array([2, 1, 3])\n",
        "print(\"Second vector:\", B)\n",
        "\n",
        "# Using 'np.cross()' function to calculate cross product\n",
        "cross_prod_AB = np.cross(A, B)\n",
        "print(\"Cross Product:\", cross_prod_AB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First vector: [3 2 3]\n",
            "Second vector: [2 1 3]\n",
            "Cross Product: [ 3 -3 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBgw81kfbZZh"
      },
      "source": [
        "Hence, we obtained the cross product of vectors $\\vec A$ and $\\vec B$ which is vector, hence has components in all the three dimensions as the input vectors.\n",
        "\n",
        "Let's verify the direction of the resultant vector by plotting the plane spanning across vectors $\\vec A$, $\\vec B$ and the resulting cross product of these two vectors:\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/whjr-v2-prod-bucket/0db92848-e803-4490-a62c-e369d9c81b1e.png width=600></center>\n",
        "\n",
        "In the above graph we can observe the plane passing through the vectors $\\vec A$, and $\\vec B$ is indicated in green and the resultant vector $\\vec A \\times \\vec B$ is orthogonal (perpendicular) to the plane.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4hbgy9rbZEf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh-GJzeLLmI_"
      },
      "source": [
        "**DOT PRODUCT OF VECTORS**\n",
        "\n",
        "Mathematically the **dot product** of two vectors $\\vec a$ and $\\vec b$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec a \\cdot \\vec b = |\\vec a| |\\vec b| \\text{cos} \\space \\theta\n",
        "\\tag{3.4}\n",
        "\\end{equation}\n",
        "\n",
        "Where, $\\theta$ is the angle between vectors $\\vec a$ and $\\vec b$. The result of this dot product is a scalar value. Hence, it is also commonly known as **scalar Product** or **inner Product** of two vectors.\n",
        "\n",
        "**Dot product in matrix notation:**\n",
        "\n",
        "\n",
        "Let us represent the vectors $\\vec{a}$ and $\\vec{b}$ in matrix form as follows:\n",
        "\n",
        "\\begin{matrix}  \n",
        "{a} = \\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3 \\\\ \\vdots \\\\ a_n \\end{bmatrix}_{n \\times 1} &\n",
        "{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n \\end{bmatrix}_{n \\times 1}\n",
        "\\end{matrix}  \n",
        "\n",
        "The dot product of $\\vec{a}$ and $\\vec{b}$ can also be calculated as:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec a \\cdot \\vec b = [(a_1 b_1) + (a_2 b_2) + (a_3 b_3) + \\dots + (a_n b_n)]\n",
        "\\tag{3.5}\n",
        "\\end{equation}\n",
        "\n",
        "If we try to multiply the above two vectors $\\vec{a}$ and $\\vec{b}$ using matrix multiplication, their product will not be defined. This is because, as per the rules of matrix multiplication, the number of columns of the first matrix must match the number of rows of the second matrix.\n",
        "\n",
        "To rectify this problem, we can take transpose of the first matrix, turning it into a $1 n$ row matrix as follows:\n",
        "\n",
        "\\begin{matrix}  \n",
        "a^T = \\begin{bmatrix} a_1 & a_2 & a_3 & \\cdots & a_n \\end{bmatrix}_{1 \\times n} &&\n",
        "{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n \\end{bmatrix}_{n \\times 1}\n",
        "\\end{matrix}  \n",
        "\n",
        "After taking transpose of $\\vec{a}$, the product of vectors $\\vec{a}$ and $\\vec{b}$ is now well-defined as the number of columns of $\\vec{a}$ is now equal to the number of rows of  $\\vec{b}$ .\n",
        "\n",
        "\n",
        "\\begin{align}  \n",
        "a^Tb &= \\begin{bmatrix} a_1 & a_2 & a_3 & \\cdots & a_n \\end{bmatrix} \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n \\end{bmatrix} \\\\\n",
        "&= [(a_1 b_1) + (a_2 b_2) + (a_3 b_3) + \\dots + (a_n b_n)]\n",
        "\\end{align}  \n",
        "\n",
        "You may observe that the result of  above matrix multiplication $a^Tb$ is equivalent to the dot product of $\\vec{a} . \\vec{b}$ (Equation $3.2$).\n",
        "\n",
        "Thus,\n",
        "\\begin{equation}\n",
        "\\boxed{\\vec a \\cdot \\vec b = a^Tb}\n",
        "\\tag{3.6}\n",
        "\\end{equation}\n",
        "\n",
        "In Python, we can obtain dot product of two vectors or matrices using `dot()` function of `numpy` module.\n",
        "\n",
        "Let us find the dot product of following two vectors:\n",
        "\n",
        "\\begin{align}\n",
        "\\vec{A} = (12, 3, 4) &&  \\vec{B} = (10, 20, 30)\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHMlAJxuHruR",
        "outputId": "d5c3fb40-9997-4336-db66-f8bef1a24c7a"
      },
      "source": [
        "# Finding dot product of two vectors\n",
        "\n",
        "# First vector\n",
        "A = np.array([12, 3, 4])\n",
        "print(\"First vector:\", A)\n",
        "\n",
        "# Second vector\n",
        "B = np.array([10, 20, 30])\n",
        "print(\"Second vector:\", B)\n",
        "\n",
        "# Using 'np.dot()' function to calculate dot product\n",
        "dot_prod_AB = np.dot(A, B)\n",
        "print(\"Dot Product:\", dot_prod_AB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First vector: [12  3  4]\n",
            "Second vector: [10 20 30]\n",
            "Dot Product: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClBWrI47HruR"
      },
      "source": [
        "Hence, we obtained the dot product of vectors $\\vec A$ and $\\vec B$ which is a scalar value.\n",
        "\n",
        "One important use of dot products is in projection of one vector onto another vector. Let us understand this concept as it is the core of PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXHUK_xzHruR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUIJjNW2Ivc5"
      },
      "source": [
        "#### Activity 4: Projection of Vectors\n",
        "\n",
        "Let's say we have two vectors $\\vec u$ and $\\vec v$ and the vector $\\vec u$ makes an angle $\\theta$ with respect to vector $\\vec v$ as shown in image below:\n",
        "\n",
        "<center><img src=https://s3-whjr-v2-prod-bucket.whjr.online/a59e9078-e6ed-4aad-b39c-f11f9dd821d0.png width = 700></center>\n",
        "\n",
        "Imagine a light source, parallel to $\\vec v$ , above $\\vec u$. The light would cast rays perpendicular or orthogonal to $\\vec v$.\n",
        "\n",
        "$g$ is the shadow cast by $\\vec u$ on $\\vec v$. This shadow vector is known as the **projection** of vector $\\vec u$ on vector $\\vec v$.\n",
        "\n",
        " The line segment $g$ indicates the magnitude or length of this shadow vector and is also known as the **projection** of $\\vec u$ on $\\vec v$ or $\\text{proj}_\\vec{v} \\vec {u}$. Let us determine the value  of $g$.\n",
        "\n",
        "**Projection  of $\\vec u$ on $\\vec v$:**\n",
        "\n",
        "We know that as per the trigonometry ratios of an angle $θ$  in a right-angled triangle:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{cos} \\space \\theta &= \\frac{\\text {Base}}{\\text {Hypotenuse}}\n",
        "\\end{align}\n",
        "\n",
        "In the above image,\n",
        "- $\\text{Base} = g$\n",
        "- $\\text{Hypotenuse} = |\\vec {u}|$\n",
        "\n",
        "Therefore,\n",
        "\n",
        "\\begin{align}\n",
        "\\text{cos} \\space \\theta &= \\frac{\\text {g}}{|\\vec {u}|}\n",
        "\\end{align}\n",
        "\n",
        "This can be rewritten as:\n",
        "\\begin{align}\n",
        "\\text {g} &= |\\vec {u}| \\text{cos} \\space \\theta \\\\\n",
        "\\tag{4.1}\n",
        "\\end{align}\n",
        "\n",
        "Recall the dot product formula of two vectors (equation $(3.1)$):\n",
        "\n",
        "\\begin{align}\n",
        "\\vec u . \\vec v &= |\\vec u| |\\vec v| \\text{cos} \\space \\theta \\\\\n",
        "\\Rightarrow\n",
        "\\text{cos} \\space \\theta &= \\frac{\\vec u . \\vec v }{|\\vec u| |\\vec v|}\n",
        "\\tag{4.2}\n",
        "\\end{align}\n",
        "\n",
        "Let us substitute this value of   $\\text{cos} \\space \\theta$ in the equation $(4.1)$.\n",
        "\n",
        "\\begin{align}\n",
        "\\text {g} &= |\\vec {u}| \\times  \\frac{\\vec u . \\vec v }{|\\vec u| |\\vec v|} \\\\\n",
        "&= \\frac{\\vec u . \\vec v }{|\\vec v|} \\\\\n",
        "\\end{align}\n",
        "\n",
        "Thus, the formula for calculating the projection of vector $\\vec u$ onto another vector $\\vec v$ is:\n",
        "\n",
        "\\begin{equation}\n",
        "\\boxed{\\text{proj}_{\\vec{v} \\vec {u}} = \\frac{\\vec u . \\vec v }{|\\vec v|}}\n",
        "\\tag{4.3}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Now that we have explored all the necessary concepts needed to understand the working of PCA, let us now learn how to determine the desired principal components or vectors mathematically.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOHH4A7skbCo"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COMH4OKDb5B5"
      },
      "source": [
        "#### Mathematics of Principal Components\n",
        "\n",
        "In PCA, we start with $d$-dimensional vectors, and want to summarise them by projecting them\n",
        "down into a $k$-dimensional subspace, where $k <= d$. Hence, we need to project original vectors onto the $k$ directions. These $k$-directions are nothing but the principal components.\n",
        "\n",
        "**Q:** How to derive these principal components mathematically?\n",
        "\n",
        "**A:** To derive these principal components, find the projections which maximize the variance.\n",
        "\n",
        "Let us understand this concept with the help of an example.  Consider the following two-dimensional dataset.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/cd975e30-9fdd-4ddb-bf2e-22a47e246254.png\"/></center>\n",
        "\n",
        "\n",
        "It appears that both the variables are highly and positively correlated with one another and most of the points lie along the <font color=red><b>\n",
        "red</font></b> line as shown in the image below:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/cd7f92ff-9b48-427d-bade-e1e306671147.png\"/></center>\n",
        "\n",
        "As such, we could reorient the axes to be centered on the data and parallel to the line above.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/6d04fa50-0e30-4ed8-864c-202f34bd86a4.png\"/></center>\n",
        "\n",
        "Let's project each observation onto the primary axis.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/b5992a88-f0d1-4939-99ca-566a3bd4785f.png\"/></center>\n",
        "\n",
        "Now, every observation lies on the primary axis.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/31d3b6c2-cbb5-4f05-8535-4942f4fbf215.png\"/></center>\n",
        "\n",
        "Hence, we just compressed a two-dimensional dataset into one dimension by translating and rotating our axes. After this transformation, we only really have one relevant dimension and thus we can discard the second axis as shown in image below:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/f9468a34-b08f-4f9f-a991-949075dcdd79.png\"/></center>\n",
        "\n",
        "If we compare the original observations with our new projections, we can see that it's not an exact representation of our data (refer the image below).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/fbb3b9a7-aad4-405b-94d2-b901f354c4b2.png\"/></center>\n",
        "\n",
        "The distance between original observations and projections is a measure of information loss. Thus, the primary axis or first principal component is chosen in such a way that it gives minimum distance between projections and observations and thereby, less information loss.\n",
        "\n",
        "\n",
        "Let us observe the above dataset in a different way. Observe the spread of the data along the green and orange directions.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/e4755ec5-6f56-4dd0-a03d-f1dbd011a716.png\"/></center>\n",
        "\n",
        "Projecting our observations onto the orange vector would result in much more information loss as compared to projecting onto the green vector. Thus, the green vector not only captures the maximum variance of the data, but also minimises the distance between observations and their projections onto the vector.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/19a196ed-d72d-4c01-a7ee-e7872dd6fecd.png\"/></center>\n",
        "\n",
        "Hence, we can say that:\n",
        "\n",
        "In PCA, minimising projection error or information loss can be accomplished by finding the direction of maximum variance within the data.\n",
        "\n",
        "Let us learn how to find the vector that carries maximum variance in data mathematically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYL1C44t2RzR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osNB0QEIUL8p"
      },
      "source": [
        "#### Activity 5: Maximising  Variance\n",
        "\n",
        "Given the set of observations ${x_i}$  in a $d$-dimensional dataset where, $i = 1, 2, …, N$.\n",
        "\n",
        "Our goal is to find the projection of $x_i$ onto a space with dimensions $k < d$ such that it gives maximum variance.\n",
        "\n",
        "We’ll start by looking for a one-dimensional projection. We define a vector $u_1$ as the direction of the lower-dimensional space.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/4ebdf0ff-eafb-440d-b0e7-361f804bc732.jpg\"/></center>\n",
        "\n",
        "Since we are only interested in the direction of  this vector, we will consider $u_1$ to be a unit vector i.e. $|\\vec u_1| = 1$.\n",
        "\n",
        "The projection of a data vector $x_i$ onto\n",
        "the unit vector $\\vec u$ can be given as:\n",
        "\\begin{equation}\n",
        "\\text{proj}_\\vec{u_1} \\vec {x_i}=\\frac{\\vec u_1 . \\vec x_i }{|\\vec u_1|}\n",
        "\\tag{from equation 4.3 }\n",
        "\\end{equation}\n",
        "\n",
        "As, $|\\vec u_1| = 1$ and $\\vec u_1 . \\vec x_i = u_1^T.x$ (from equation $3.3$),\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{proj}_\\vec{u_1} \\vec {x_i}= u_1^T.x_i\n",
        "\\tag{5.1}\n",
        "\\end{equation}\n",
        "\n",
        "If $\\bar{x}$ is the mean of the data observations $x_i$ in the original space, then the mean of $x_i$ in the projected space is given by:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{proj}_\\vec{u_1} \\bar {x}= u_1^T.\\bar{x}\n",
        "\\tag{5.2}\n",
        "\\end{equation}\n",
        "\n",
        "**Calculating variance:**\n",
        "\n",
        "The variance of a dataset from its mean is calculated by finding the difference between each data value and the mean, squaring the differences and then finding the sum of all squared differences.\n",
        "\n",
        "Thus, the variance of projections is given as:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\text {var}(x_i) &= \\frac{1}{N} \\sum\\limits_{i = 1}^N \\bigg[\\text{proj}_\\vec{u_1} \\vec {x_i} - \\text{proj}_\\vec{u_1} \\bar {x}\\bigg]^2 \\\\\n",
        "&= \\frac{1}{N} \\sum\\limits_{i = 1}^N \\bigg[u_1^T.x_i - u_1^T.\\bar{x}\\bigg]^2 \\\\\n",
        "&= \\frac{1}{N} \\sum\\limits_{i = 1}^N \\bigg[u_1^T .(x_i - \\bar{x})\\bigg]^2 \\\\\n",
        "&= \\frac{1}{N} \\sum\\limits_{i = 1}^N \\underbrace{\\bigg[u_1^T . (x_i - \\bar{x})\\bigg]}_\\text{1st term} \\underbrace{\\bigg[u_1^T . (x_i - \\bar{x})\\bigg]}_\\text{2nd term} \\\\ \\\\\n",
        "\\end{align}\n",
        "\n",
        "The $2^{nd}$ term in the above equation can also be written as : $\\bigg[u_1. (x_i - \\bar{x})^T\\bigg]$ as both $u_1$ and $(x_i - \\bar{x})$ are vectors and their dot product will be same no matter in whichever order we take transpose i.e.\n",
        "\n",
        "$\\bigg[u_1^T. (x_i - \\bar{x})\\bigg] \\equiv \\bigg[u_1. (x_i - \\bar{x})^T\\bigg]$\n",
        "\n",
        "Thus,\n",
        "\n",
        "\\begin{align}\n",
        "\\text {var}(x_i) &= \\frac{1}{N} \\sum\\limits_{i = 1}^N \\bigg[u_1^T . (x_i - \\bar{x})\\bigg]\\bigg[u_1 . (x_i - \\bar{x})^T\\bigg] \\\\\n",
        "&= u_1^T. u_1.\\frac{1}{N} \\sum\\limits_{i = 1}^N \\bigg[(x_i - \\bar{x}).(x_i - \\bar{x})^T \\bigg] \\\\\n",
        "&= u_1^T. S. u_1 \\\\\n",
        "\\end{align}\n",
        "\n",
        "Where, $S$ is the  covariance matrix of the observed data in the original high dimensional space.\n",
        "\n",
        "\n",
        "$S = \\frac{1}{N} \\sum\\limits_{i = 1}^N \\bigg[(x_i - \\bar{x}).(x_i - \\bar{x})^T \\bigg]$\n",
        "\n",
        "**Note:** Such covariance matrix is known as **closed form of covariance matrix**. We will not explore this in much detail.\n",
        "\n",
        "Thus,\n",
        "\\begin{align}\n",
        "\\text {var}(x_i) = u_1^T. S. u_1\n",
        "\\end{align}\n",
        "\n",
        "Our goal is to obtain a vector $u_1$ such that it  maximises variance of projections i.e. $\\text{var}(x_i)$ with the constraint $|u_1| = 1$ or $u_1^T. u_1 = 1$.\n",
        "\n",
        "Thus, the maximisation function looks like this:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{max} \\space && u_1^T. S. u_1 \\\\\n",
        "\\text{subject to} \\space && u_1^T. u_1 = 1\n",
        "\\end{align}\n",
        "\n",
        "Such problems of constrained optimization can be solved easily using **Lagrangian multipliers**.\n",
        "This technique says that if we need to maximise a function $f(x)$ subject to constraint $g(x)=c$, we introduce the Lagrange multiplier $\\lambda$ and construct the Lagrangian $\\mathcal{L}(x, \\lambda)$:\n",
        "\n",
        "$$\\mathcal{L}(x, \\lambda) = f(x) - \\lambda (g(x) - c)$$\n",
        "\n",
        "In our case,\n",
        "- $f(x) = u_1^T. S. u_1$\n",
        "- $g(x) = u_1^T. u_1$\n",
        "- $c = 1$\n",
        "\n",
        "Thus, our Lagrangian is:\n",
        "\n",
        "$$\\mathcal{L}(u_1, \\lambda_1) = u_1^T. S. u_1 - \\lambda_1 (u_1^T. u_1 - 1)$$\n",
        "\n",
        "Taking partial derivative of above lagrangian function with respect to $u_1$,\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial u_1} = 2.S.u_1 - 2 .\\lambda_1. u_1\n",
        "\\tag{5.3}\n",
        "\\end{align}\n",
        "\n",
        "**Note:** We will not get into details of how to take partial derivatives of vectors. You can refer the following examples to understand common vector derivative. They look similar to scalar ones, hence you can memorise them easily. In these examples, $b$ is a constant scalar, and $B$ is a constant matrix.\n",
        "\n",
        "<img src=\"https://s3-whjr-v2-prod-bucket.whjr.online/5878b96e-c166-422c-9d1d-dad77589a6b8.PNG\"/>\n",
        "\n",
        "is beyond the scope\n",
        "equating the above equation to $0$, we get\n",
        "\\begin{align}\n",
        "2.S.u_1 - 2 .\\lambda_1. u_1 = 0 \\\\\n",
        "S.u_1 - \\lambda_1. u_1 = 0 \\\\\n",
        "\\boxed{S.u_1 = \\lambda_1. u_1} \\tag{5.4}\n",
        "\\end{align}\n",
        "\n",
        "This desired vector $u_1$ is nothing but an **eigenvector** of the covariance matrix $S$, and the maximum variance is equal to the **eigenvalue** $\\lambda_1$. This is good news because, all you need to do is find eigenvectors having the largest eigenvalue and you will get your principal component or the desired dimension.\n",
        "\n",
        "Similarly, we can obtain additional principal components  by choosing directions that maximise variance while being orthogonal to the existing ones.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh7romO_MCko"
      },
      "source": [
        "---"
      ]
    }
  ]
}